
@article{infanger_p_2019,
	title = {P value functions: {An} underused method to present research results and to promote quantitative reasoning},
	volume = {38},
	issn = {1097-0258},
	shorttitle = {P value functions},
	doi = {10.1002/sim.8293},
	abstract = {Null hypothesis significance testing has received a great amount of attention in recent years in the light of the reproducibility crisis of science. Recently, there have been calls to retire the dichotomization of study results into "significant" or "not significant" depending on whether the P value crosses some threshold or not. Ways of improving the interpretation of P values and confidence intervals are therefore needed. We illustrate the use of P value functions, which display confidence limits and P values for any confidence level for a parameter. P value functions accessibly display a wealth of information: point estimate for the parameter, one-sided and two-sided confidence limits at any level, and one-sided and two-sided P values for any null and non-null value and the counternull value. Presenting several recent examples from the literature, we show how P value functions can be applied to present evidence and to make informed statistical inferences without resorting to dichotomization. We argue that P value functions are more informative than commonly used summaries of study results such as single P values or confidence intervals. P value functions require minimal retraining, are easily interpreted, and show potential to fix many of the common misinterpretation of P values and confidence intervals. To facilitate the adoption of P value functions, we released an R package for creating P value functions for several commonly used estimates.},
	language = {eng},
	number = {21},
	journal = {Statistics in Medicine},
	author = {Infanger, Denis and Schmidt-Trucksäss, Arno},
	month = sep,
	year = {2019},
	pmid = {31270842},
	keywords = {Biometry, confidence interval, Confidence Intervals, Data Interpretation, Statistical, graphics, Humans, hypothesis testing, P value, statistical significance},
	pages = {4189--4197},
}

@article{greenland_statistical_2016,
	title = {Statistical tests, {P} values, confidence intervals, and power: a guide to misinterpretations},
	volume = {31},
	issn = {1573-7284},
	shorttitle = {Statistical tests, {P} values, confidence intervals, and power},
	url = {https://doi.org/10.1007/s10654-016-0149-3},
	doi = {10.1007/s10654-016-0149-3},
	abstract = {Misinterpretation and abuse of statistical tests, confidence intervals, and statistical power have been decried for decades, yet remain rampant. A key problem is that there are no interpretations of these concepts that are at once simple, intuitive, correct, and foolproof. Instead, correct use and interpretation of these statistics requires an attention to detail which seems to tax the patience of working scientists. This high cognitive demand has led to an epidemic of shortcut definitions and interpretations that are simply wrong, sometimes disastrously so—and yet these misinterpretations dominate much of the scientific literature. In light of this problem, we provide definitions and a discussion of basic statistics that are more general and critical than typically found in traditional introductory expositions. Our goal is to provide a resource for instructors, researchers, and consumers of statistics whose knowledge of statistical theory and technique may be limited but who wish to avoid and spot misinterpretations. We emphasize how violation of often unstated analysis protocols (such as selecting analyses for presentation based on the P values they produce) can lead to small P values even if the declared test hypothesis is correct, and can lead to large P values even if that hypothesis is incorrect. We then provide an explanatory list of 25 misinterpretations of P values, confidence intervals, and power. We conclude with guidelines for improving statistical interpretation and reporting.},
	language = {en},
	number = {4},
	urldate = {2025-08-18},
	journal = {European Journal of Epidemiology},
	author = {Greenland, Sander and Senn, Stephen J. and Rothman, Kenneth J. and Carlin, John B. and Poole, Charles and Goodman, Steven N. and Altman, Douglas G.},
	month = apr,
	year = {2016},
	keywords = {Confidence intervals, Hypothesis testing, Null testing, P value, Power, Significance tests, Statistical testing},
	pages = {337--350},
	file = {Full Text PDF:C\:\\Users\\denis\\Zotero\\storage\\3I6WLP7U\\Greenland et al. - 2016 - Statistical tests, P values, confidence intervals, and power a guide to misinterpretations.pdf:application/pdf},
}

@article{bender_tutorial_2005,
	title = {Tutorial: {Using} {Confidence} {Curves} in {Medical} {Research}},
	volume = {47},
	copyright = {Copyright © 2005 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim},
	issn = {1521-4036},
	shorttitle = {Tutorial},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.200410104},
	doi = {10.1002/bimj.200410104},
	abstract = {Confidence intervals represent a routinely used standard method to document the uncertainty of estimated effects. In most cases, for the calculation of confidence intervals the conventional fixed 95\% confidence level is used. Confidence curves represent a graphical illustration of confidence intervals for confidence levels varying between 0 and 100\%. Although such graphs have been repeatedly proposed under different names during the last 40 years, confidence curves are rarely used in medical research. In this paper, we introduce confidence curves and present a short historical review. We draw attention to the different interpretation of one- and two-sided statistical inference. It is shown that these two options also have influence on the plotting of appropriate confidence curves. We illustrate the use of one- and two-sided confidence curves and explain their correct interpretation. In medical research more emphasis on the choice between the one- and two-sided approaches should be given. One- and two-sided confidence curves are useful complements to the conventional methods of presenting study results. (© 2005 WILEY-VCH Verlag GmbH \& Co. KGaA, Weinheim)},
	language = {en},
	number = {2},
	urldate = {2025-08-18},
	journal = {Biometrical Journal},
	author = {Bender, Ralf and Berg, Gabriele and Zeeb, Hajo},
	year = {2005},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.200410104},
	keywords = {Confidence curves, Confidence intervals, Effect size, Graphical methods, Hypothesis testing, One-sided hypotheses, Statistical significance},
	pages = {237--247},
	file = {Full Text PDF:C\:\\Users\\denis\\Zotero\\storage\\UERAWBK9\\Bender et al. - 2005 - Tutorial Using Confidence Curves in Medical Research.pdf:application/pdf;Snapshot:C\:\\Users\\denis\\Zotero\\storage\\XWYUHGBM\\bimj.html:text/html},
}

@article{rafi_semantic_2020,
	title = {Semantic and cognitive tools to aid statistical science: replace confidence and significance by compatibility and surprise},
	volume = {20},
	issn = {1471-2288},
	shorttitle = {Semantic and cognitive tools to aid statistical science},
	url = {https://doi.org/10.1186/s12874-020-01105-9},
	doi = {10.1186/s12874-020-01105-9},
	abstract = {Researchers often misinterpret and misrepresent statistical outputs. This abuse has led to a large literature on modification or replacement of testing thresholds and P-values with confidence intervals, Bayes factors, and other devices. Because the core problems appear cognitive rather than statistical, we review some simple methods to aid researchers in interpreting statistical outputs. These methods emphasize logical and information concepts over probability, and thus may be more robust to common misinterpretations than are traditional descriptions.},
	language = {en},
	number = {1},
	urldate = {2025-08-18},
	journal = {BMC Medical Research Methodology},
	author = {Rafi, Zad and Greenland, Sander},
	month = sep,
	year = {2020},
	keywords = {Bias, Cognitive science, Confidence intervals, Data interpretation, Evidence, Hypothesis tests, Information, Models, statistical, P-values, Statistical significance},
	pages = {244},
	file = {Full Text PDF:C\:\\Users\\denis\\Zotero\\storage\\QLA8YCVL\\Rafi und Greenland - 2020 - Semantic and cognitive tools to aid statistical science replace confidence and significance by comp.pdf:application/pdf},
}

@article{rosenthal_counternull_1994,
	title = {The {Counternull} {Value} of an {Effect} {Size}: {A} {New} {Statistic}},
	volume = {5},
	issn = {0956-7976},
	shorttitle = {The {Counternull} {Value} of an {Effect} {Size}},
	url = {https://doi.org/10.1111/j.1467-9280.1994.tb00281.x},
	doi = {10.1111/j.1467-9280.1994.tb00281.x},
	abstract = {We introduce a new, readily computed statistic, the counternull value of an obtained effect size, which is the nonnull magnitude of effect size that is supported by exactly the same amount of evidence as supports the null value of the effect size In other words, if the counternull value were taken as the null hypothesis, the resulting p value would be the same as the obtained p value for the actual null hypothesis Reporting the counternull, in addition to the p value, virtually eliminates two common errors (a) equating failure to reject the null with the estimation of the effect size as equal to zero and (b) taking the rejection of a null hypothesis on the basis of a significant p value to imply a scientifically important finding In many common situations with a one-degree-of-freedom effect size, the value of the counternull is simply twice the magnitude of the obtained effect size, but the counternull is defined in general, even with multi-degree-of-freedom effect sizes, and therefore can be applied when a confidence interval cannot be The use of the counter-null can be especially useful in meta-analyses when evaluating the scientific importance of summary effect sizes},
	language = {EN},
	number = {6},
	urldate = {2025-08-18},
	journal = {Psychological Science},
	author = {Rosenthal, Robert and Rubin, Donald B.},
	month = nov,
	year = {1994},
	note = {Publisher: SAGE Publications Inc},
	pages = {329--334},
}

@article{poole_beyond_1987,
	title = {Beyond the confidence interval.},
	volume = {77},
	issn = {0090-0036},
	url = {https://ajph.aphapublications.org/doi/abs/10.2105/AJPH.77.2.195},
	doi = {10.2105/AJPH.77.2.195},
	number = {2},
	urldate = {2025-08-18},
	journal = {American Journal of Public Health},
	author = {Poole, C},
	month = feb,
	year = {1987},
	note = {Publisher: American Public Health Association},
	pages = {195--199},
}

@article{poole_confidence_1987,
	title = {Confidence intervals exclude nothing.},
	volume = {77},
	issn = {0090-0036},
	url = {https://ajph.aphapublications.org/doi/abs/10.2105/AJPH.77.4.492},
	doi = {10.2105/AJPH.77.4.492},
	number = {4},
	urldate = {2025-08-18},
	journal = {American Journal of Public Health},
	author = {Poole, C},
	month = apr,
	year = {1987},
	note = {Publisher: American Public Health Association},
	pages = {492--493},
}

@article{greenland_valid_2019,
	title = {Valid {P}-{Values} {Behave} {Exactly} as {They} {Should}: {Some} {Misleading} {Criticisms} of {P}-{Values} and {Their} {Resolution} {With} {S}-{Values}},
	volume = {73},
	issn = {0003-1305},
	shorttitle = {Valid {P}-{Values} {Behave} {Exactly} as {They} {Should}},
	url = {https://doi.org/10.1080/00031305.2018.1529625},
	doi = {10.1080/00031305.2018.1529625},
	abstract = {The present note explores sources of misplaced criticisms of P-values, such as conflicting definitions of “significance levels” and “P-values” in authoritative sources, and the consequent misinterpretation of P-values as error probabilities. It then discusses several properties of P-values that have been presented as fatal flaws: That P-values exhibit extreme variation across samples (and thus are “unreliable”), confound effect size with sample size, are sensitive to sample size, and depend on investigator sampling intentions. These properties are often criticized from a likelihood or Bayesian framework, yet they are exactly the properties P-values should exhibit when they are constructed and interpreted correctly within their originating framework. Other common criticisms are that P-values force users to focus on irrelevant hypotheses and overstate evidence against those hypotheses. These problems are not however properties of P-values but are faults of researchers who focus on null hypotheses and overstate evidence based on misperceptions that p = 0.05 represents enough evidence to reject hypotheses. Those problems are easily seen without use of Bayesian concepts by translating the observed P-value p into the Shannon information (S-value or surprisal) –log2(p).},
	number = {sup1},
	urldate = {2025-08-18},
	journal = {The American Statistician},
	author = {Greenland, Sander},
	month = mar,
	year = {2019},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1080/00031305.2018.1529625},
	keywords = {Compatibility, Dichotomania, Evidence, Information, Logworth, Nullism, P-values, S-values, Significance testing, Surprisal},
	pages = {106--114},
	file = {Full Text PDF:C\:\\Users\\denis\\Zotero\\storage\\FNRZVA2M\\Greenland - 2019 - Valid P-Values Behave Exactly as They Should Some Misleading Criticisms of P-Values and Their Resol.pdf:application/pdf},
}

@article{greenland_valid_2019-1,
	title = {Valid {P}-{Values} {Behave} {Exactly} as {They} {Should}: {Some} {Misleading} {Criticisms} of {P}-{Values} and {Their} {Resolution} {With} {S}-{Values}},
	volume = {73},
	issn = {0003-1305},
	shorttitle = {Valid {P}-{Values} {Behave} {Exactly} as {They} {Should}},
	url = {https://doi.org/10.1080/00031305.2018.1529625},
	doi = {10.1080/00031305.2018.1529625},
	abstract = {The present note explores sources of misplaced criticisms of P-values, such as conflicting definitions of “significance levels” and “P-values” in authoritative sources, and the consequent misinterpretation of P-values as error probabilities. It then discusses several properties of P-values that have been presented as fatal flaws: That P-values exhibit extreme variation across samples (and thus are “unreliable”), confound effect size with sample size, are sensitive to sample size, and depend on investigator sampling intentions. These properties are often criticized from a likelihood or Bayesian framework, yet they are exactly the properties P-values should exhibit when they are constructed and interpreted correctly within their originating framework. Other common criticisms are that P-values force users to focus on irrelevant hypotheses and overstate evidence against those hypotheses. These problems are not however properties of P-values but are faults of researchers who focus on null hypotheses and overstate evidence based on misperceptions that p = 0.05 represents enough evidence to reject hypotheses. Those problems are easily seen without use of Bayesian concepts by translating the observed P-value p into the Shannon information (S-value or surprisal) –log2(p).},
	number = {sup1},
	urldate = {2025-08-18},
	journal = {The American Statistician},
	author = {Greenland, Sander},
	month = mar,
	year = {2019},
	note = {Publisher: ASA Website
\_eprint: https://doi.org/10.1080/00031305.2018.1529625},
	keywords = {Compatibility, Dichotomania, Evidence, Information, Logworth, Nullism, P-values, S-values, Significance testing, Surprisal},
	pages = {106--114},
	file = {Full Text PDF:C\:\\Users\\denis\\Zotero\\storage\\3ACMUZ7A\\Greenland - 2019 - Valid P-Values Behave Exactly as They Should Some Misleading Criticisms of P-Values and Their Resol.pdf:application/pdf},
}
